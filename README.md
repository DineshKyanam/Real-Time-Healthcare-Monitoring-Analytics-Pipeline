ğŸ¥ Healthcare Compliance Automation â€” End-to-End Real-Time Data Engineering Pipeline

A complete healthcare data engineering project built using Kafka, Spark Structured Streaming, Delta Lake, Airflow, and Power BI to automate PHI/PII masking, enforce HIPAA-friendly data handling, orchestrate ETL workflows, and generate hospital insights dashboards.

ğŸ–¼ï¸ Architecture Diagram

This diagram illustrates the real-time flow of health data from ingestion â†’ masking â†’ Delta Lake â†’ Airflow â†’ Power BI dashboards.

ğŸš€ Project Overview

This platform simulates a real-world healthcare compliance system capable of:

âœ” Streaming patient data in real-time
âœ” Performing PHI/PII masking
âœ” Validating, cleaning, and deduplicating records
âœ” Storing data in Delta Lake (Bronze â†’ Silver â†’ Gold)
âœ” Running scheduled healthcare ETL tasks via Airflow
âœ” Powering interactive analytics dashboards in Power BI

The full workflow is designed with HIPAA principles (masking + limited exposure) in mind.

ğŸ—ï¸ Technology Stack
Layer	Tools / Frameworks
Ingestion	Apache Kafka, Python Producer
Stream Processing	PySpark, Spark Structured Streaming
Storage	Delta Lake (Bronze/Silver/Gold)
Workflow Orchestration	Apache Airflow
Analytics	Power BI
Containerization	Docker, Docker Compose
ğŸ“ Folder Structure
healthcare-compliance-automation/
â”‚
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ healthcare_pipeline_dag.py
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ masked/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ logs/
â”‚
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ kafka_producer.py
â”‚   â””â”€â”€ sample_patient_data.csv
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ helpers.py
â”‚
â”œâ”€â”€ spark_streaming/
â”‚   â”œâ”€â”€ streaming_job.py
â”‚   â”œâ”€â”€ masking_functions.py
â”‚   â””â”€â”€ configs/
â”‚
â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ healthcare_overview.pbix
â”‚   â””â”€â”€ screenshots/
â”‚
â””â”€â”€ docker-compose.yml

ğŸ” PHI/PII Masking Logic

All sensitive medical fields are masked for compliance:

Field	Masking Applied
Name	Only first letter visible (J*****)
SSN	Last 4 digits visible only
Phone	Middle digits masked
Email	First 2 letters + domain masked
DOB	Year retained only
Address	Only City, State preserved

These transformations follow HIPAA de-identification principles.

âš¡ Real-Time Stream Processing Flow
âœ” Kafka Producer

Reads healthcare CSV/JSON files

Converts to JSON messages

Publishes to Kafka topic: healthcare.data

âœ” Spark Structured Streaming

Performs:

Schema validation

Null handling

PHI/PII masking

Deduplication

Writes to Delta Lake in 3 layers:

Bronze â†’ Raw Data  
Silver â†’ Cleaned + Masked  
Gold   â†’ Aggregated Analytics

ğŸŒ€ Airflow DAG â€” Healthcare Pipeline

The DAG handles:

Daily ETL

Data quality checks

Logging & alerts

Gold-layer table generation

Exporting curated data for analytics

Airflow UI:
http://localhost:8080

ğŸ“Š Power BI Analytics Dashboards

Included dashboards:

ğŸŸ¦ 1. Patient Admissions

Daily/weekly/monthly patient inflow

Department-level analysis

Admission trends

ğŸŸ¦ 2. Diagnosis Trends

Top diagnoses

Severity categories

Treatment volume by department

ğŸŸ¦ 3. Hospital Operational KPIs

Bed occupancy rate

Avg length of stay

Doctor & department performance

ğŸŸ¦ 4. Compliance Monitoring

Missing PHI counts

Masking success rates

Validation failures

Dashboards are available in:

dashboards/healthcare_overview.pbix
dashboards/screenshots/

â–¶ï¸ How to Run the Pipeline
1. Start Kafka, Zookeeper, Airflow
docker-compose up -d

2. Run Producer
python producer/kafka_producer.py

3. Start Spark Streaming
spark-submit spark_streaming/streaming_job.py

4. Trigger Airflow DAG

In Airflow UI â†’ Run:
healthcare_pipeline_dag

5. Open Power BI Dashboard

Load:
dashboards/healthcare_overview.pbix

ğŸ¯ Key Features Recruiters Will Love

âœ” End-to-end real-time data engineering project
âœ” Full Delta Lake architecture implementation
âœ” Healthcare PHI/PII masking and compliance
âœ” Airflow DAG with DQ checks
âœ” Power BI dashboards for hospital insights
âœ” Clean, production-style folder structure
âœ” Docker-based reproducible environment
âœ” Professional documentation & diagram

ğŸ§‘â€ğŸ’» Author

Dinesh Kyanam
Data Engineer | Real-Time Streaming | Cloud | Big Data
ğŸ”— GitHub: your link
ğŸ”— LinkedIn: your link

